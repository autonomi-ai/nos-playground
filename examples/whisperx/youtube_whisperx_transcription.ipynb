{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03f663ab-0200-47ce-bbf0-5fb4eddd6820",
   "metadata": {},
   "source": [
    "Init the WhisperX custom model on your machine with `nos serve up -c serve.yaml --env-file ./.env`.\n",
    "\n",
    "Copy `.env.template` into `.env` and populate fields (should just be `HUGGINGFACE_HUB_TOKEN`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606a3ff3-a82f-49d6-89da-02c415c246b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect NOS client to the running server\n",
    "import nos\n",
    "from nos.client import Client\n",
    "from nos.logging import logger\n",
    "\n",
    "client = Client()\n",
    "\n",
    "logger.debug(\"Waiting for server to start...\")\n",
    "client.WaitForServer()\n",
    " \n",
    "logger.debug(\"Confirming server is healthy...\")\n",
    "if not client.IsHealthy():\n",
    "    raise RuntimeError(\"NOS server is not healthy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ca93ff-ebd7-432a-a3d2-a304d014bccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import tempfile\n",
    "\n",
    "def trim_audio(audio_path: Path, duration_s: int = 600) -> Path:\n",
    "    import ffmpeg\n",
    "    with tempfile.NamedTemporaryFile(suffix=Path(audio_path).suffix, delete=False) as tmp:\n",
    "        audio_trimmed = ffmpeg.input(str(audio_path)).audio.filter(\"atrim\", duration=duration_s)\n",
    "        audio_output = ffmpeg.output(audio_trimmed, tmp.name)\n",
    "        ffmpeg.run(audio_output, overwrite_output=True)\n",
    "        return Path(tmp.name)\n",
    "\n",
    "def download_youtube_url_and_transcribe(url):\n",
    "    from yt_dlp import YoutubeDL\n",
    "\n",
    "    ydl_opts = {\n",
    "        \"format\": \"bestaudio/best\", \n",
    "        \"postprocessors\": [\n",
    "            {\n",
    "                \"key\": \"FFmpegExtractAudio\",\n",
    "                \"preferredcodec\": \"wav\",\n",
    "                \"preferredquality\": \"192\",\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    with YoutubeDL(ydl_opts) as ydl:\n",
    "        # set download location to current directory\n",
    "        info_dict = ydl.extract_info(url, download=False)\n",
    "        output_filename = ydl.prepare_filename(info_dict)\n",
    "        audio_filename = output_filename.replace(\".webm\", \".wav\")\n",
    "        error_code = ydl.download([url]) \n",
    "        assert error_code == 0\n",
    "\n",
    "    # run transcription\n",
    "    whisperx = client.Module(\"m-bain/whisperx-large-v2\")\n",
    "    assert whisperx is not None\n",
    "    assert whisperx.GetModelInfo() is not None\n",
    "\n",
    "    with client.UploadFile(trim_audio(audio_filename)) as remote_path:\n",
    "        response = whisperx.transcribe(path=remote_path, batch_size=96)\n",
    "    \n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae15b9e2-07bf-4659-aacf-662bf981e22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Youtube: Conversation with Ray Dalio\n",
    "transcription = download_youtube_url_and_transcribe(\"https://www.youtube.com/watch?v=Tfrrubw7pcE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91f78c5-b00b-4cb1-a809-6a058832aa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WhisperX breaks transcriptions into segments and segments into words tagged with a speaker ID\n",
    "transcription['segments'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4f0d44-c3e3-4aaa-9e17-44552e1d31ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join words to each speaker ID for summarization through the OpenAI chat completion API\n",
    "def join_segments(segments):\n",
    "    user_texts = {}\n",
    "    for segment in segments:\n",
    "        for word_dict in segment['words']:\n",
    "            if not 'speaker' in word_dict:\n",
    "                continue\n",
    "            speaker = word_dict['speaker']\n",
    "            if speaker not in user_texts:\n",
    "                user_texts[speaker] = []\n",
    "            user_texts[speaker].append(word_dict['word'])\n",
    "    for speaker in user_texts:\n",
    "        user_texts[speaker] = ' '.join(user_texts[speaker])\n",
    "    return user_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c8de42-abd0-4f14-92a2-87d92f904b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = join_segments(transcription['segments'])\n",
    "# double check that the audio was well transcribed\n",
    "joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33269aaf-7246-408f-99f3-bbddc42e36aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install openai if not already installed\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34932f2d-d631-4289-98ce-07b393b0fd4c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"NoneType\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 12\u001b[0m\n\u001b[1;32m      6\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://api.openai.com/v1/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAuthorization\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBearer \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mapi_key\u001b[49m,\n\u001b[1;32m     13\u001b[0m }\n\u001b[1;32m     15\u001b[0m speakers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(joined\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m     16\u001b[0m first_speaker_data \u001b[38;5;241m=\u001b[39m joined[speakers[\u001b[38;5;241m0\u001b[39m]]\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"NoneType\") to str"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "\n",
    "url = \"https://api.openai.com/v1/chat/completions\"\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": \"Bearer \" + api_key,\n",
    "}\n",
    "\n",
    "speakers = list(joined.keys())\n",
    "first_speaker_data = joined[speakers[0]]\n",
    "\n",
    "data = {\n",
    "    \"model\": \"gpt-3.5-turbo\",\n",
    "    \"messages\": [\n",
    "      {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a summarization bot for youtube videos. you provide two sentence descriptions.\"\n",
    "      },\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Summarize the following transcript: \" + first_speaker_data\n",
    "      }\n",
    "    ],\n",
    "    \"max_tokens\": 100,\n",
    "    \"temperature\": 0.3,\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, data=json.dumps(data))    \n",
    "summary = response.json()['choices'][0]['message']['content']\n",
    "print(f\"Summary: {summary}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb9ba18-ca42-42d7-98a8-7d6b46a37b05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nos",
   "language": "python",
   "name": "nos"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
